# ================================================
# APP STREAMLIT: eRVC (MASTER) + DeclaracionVerificador (EXTRANET)
# Limpieza, transformaciones, comprobaci√≥n de integridad y selector m√∫ltiple nipd
# ================================================
import sys, subprocess, pkgutil, os
import pandas as pd
import numpy as np
from io import BytesIO
import unicodedata, re
import streamlit as st

# Instalaci√≥n silenciosa si falta
def _install_if_missing(pkgs):
    for p in pkgs:
        if pkgutil.find_loader(p) is None:
            with open(os.devnull, "w") as devnull:
                subprocess.check_call([sys.executable, "-m", "pip", "install", "-q", p],
                                      stdout=devnull, stderr=devnull)
_install_if_missing(["xlsxwriter", "openpyxl", "plotly", "streamlit-shadcn-ui"])

# Importar componentes modernos de UI
try:
    import streamlit_shadcn_ui as ui
except ImportError:
    ui = None

# ------------------------------
# Utilidades
# ------------------------------
def normalize_text(s):
    if pd.isna(s) or s == "":
        return ""
    s = str(s).strip().lower()
    s = unicodedata.normalize("NFD", s)
    s = re.sub(r"[^\w\s]", "", s)
    return s

def build_normalized_map(columns):
    return {normalize_text(c): c for c in columns}

def safe_get_col(map_norm, candidates):
    for cand in candidates:
        norm_cand = normalize_text(cand)
        if norm_cand in map_norm:
            return map_norm[norm_cand]
    return None

def detect_header_row(xl_bytes, sheet_index=0, max_probe_rows=20, min_hits=3):
    try:
        for row_idx in range(max_probe_rows):
            df_test = pd.read_excel(BytesIO(xl_bytes), sheet_name=sheet_index, header=row_idx, nrows=1)
            hits = sum(1 for col in df_test.columns if any(kw in str(col).lower() for kw in ["nipd", "tiquet", "verificador", "pesnet", "nif"]))
            if hits >= min_hits:
                return row_idx
    except Exception:
        pass
    return None

def limpiar_eRVC(eRVC_df):
    """Limpia y procesa el DataFrame de eRVC seg√∫n especificaciones"""
    df = eRVC_df.copy()
    
    # Filtrar columna 'dos' para mantener solo 'CV'
    if 'dos' in df.columns:
        df = df[df['dos'] == 'CV']
    
    # Formatear dataPesada a DD/MM/AAAA (sin hora)
    if 'dataPesada' in df.columns:
        df['dataPesada'] = pd.to_datetime(df['dataPesada'], errors='coerce').dt.strftime('%d/%m/%Y')
    
    # Formatear dataGravacio a DD/MM/AAAA (sin hora)
    if 'dataGravacio' in df.columns:
        df['dataGravacio'] = pd.to_datetime(df['dataGravacio'], errors='coerce').dt.strftime('%d/%m/%Y')
    
    # Convertir columnas problem√°ticas a string para evitar errores de tipo
    string_columns = ['numPesada', 'nipd', 'nifLliurador']
    for col in string_columns:
        if col in df.columns:
            df[col] = df[col].astype(str)
    
    # Eliminar columnas especificadas
    columns_to_drop = [
        'qualificacioPesada', 
        'motiuPesadaIncidental', 
        'modificada', 
        'destiRaim', 
        'varietatDesc'
    ]
    
    existing_columns_to_drop = [col for col in columns_to_drop if col in df.columns]
    if existing_columns_to_drop:
        df.drop(columns=existing_columns_to_drop, inplace=True)
    
    return df

def limpiar_extranet(extranet_bytes, eRVC_df):
    extranet_xl = pd.ExcelFile(BytesIO(extranet_bytes))
    extranet_sheet = extranet_xl.sheet_names[0]

    hdr = detect_header_row(extranet_bytes, sheet_index=0)
    try_headers = []
    if hdr is not None: try_headers.append(hdr)
    try_headers += [6, 5]  # fallbacks comunes

    df = None
    tried = set()
    for h in try_headers:
        if h in tried: continue
        tried.add(h)
        try:
            tmp = pd.read_excel(BytesIO(extranet_bytes), sheet_name=extranet_sheet, header=h)
            if tmp.shape[1] > 1:
                df = tmp
                break
        except Exception:
            pass

    if df is None:
        raise RuntimeError("No fue posible determinar la fila de encabezados en EXTRANET.")

    # Eliminar columnas duplicadas manteniendo la primera ocurrencia
    df = df.loc[:, ~df.columns.duplicated()]
    
    # Eliminar columnas "Unnamed"
    df = df.loc[:, [c for c in df.columns if not str(c).startswith("Unnamed")]]

    colmap = build_normalized_map(df.columns)

    # D√≠a y hora -> dataPesada / Hora
    dia_hora_col = safe_get_col(colmap, ["D√≠a y hora:", "D√≠a y hora", "Dia y hora:", "Dia y hora"])
    if dia_hora_col:
        dt = pd.to_datetime(df[dia_hora_col], errors="coerce", dayfirst=True)
        if dt.isna().mean() > 0.5:
            dt = pd.to_datetime(df[dia_hora_col], errors="coerce", dayfirst=False)
        df["dataPesada"] = dt.dt.strftime("%d/%m/%Y")
        df["Hora"] = dt.dt.strftime("%H:%M:%S")
        df.drop(columns=[dia_hora_col], inplace=True)

    # Renombrados
    rename_candidates = {
        "Num. tiquet de b√°scula": "tiquetBascula",
        "NIPBD": "nipd",
        "Nombre y Apellidos Viticultor": "nomLliurador",
        "Nif Viticultor": "nifLliurador",
        "Raz√≥n Social": "nomCeller",

    }
    actual_renames = {}
    colmap = build_normalized_map(df.columns)
    for src, dst in rename_candidates.items():
        found = safe_get_col(colmap, [src])
        if found: actual_renames[found] = dst
    if actual_renames:
        df.rename(columns=actual_renames, inplace=True)

    # Tratar nipd como texto sin separadores de miles
    if 'nipd' in df.columns:
        # Convertir a string preservando el formato original
        df['nipd'] = df['nipd'].apply(lambda x: str(x).replace('.', '').replace(',', '').strip() if pd.notna(x) else '')
        
        # Eliminar el √∫ltimo cero si se a√±adi√≥ incorrectamente durante la conversi√≥n
        # Esto corrige el problema donde '2501200003' se convierte en '2501200030'
        df['nipd'] = df['nipd'].apply(lambda x: x[:-1] if x.endswith('0') and len(x) > 9 else x)

    # Eliminar columnas no deseadas
    drop_targets = [
        "modificado por", "fecha modificacion", "observaciones",
        "descarga en caja", "ecologico", "gluconico",
        "grado alcoholico verificado", "grado", "estado"
    ]
    to_drop = [col for col in df.columns if normalize_text(col) in drop_targets]
    if to_drop:
        df.drop(columns=to_drop, inplace=True)

    # Filtrar Zona ‚â† {Almendralejo, Requena, Cari√±ena}
    zona_col = safe_get_col(build_normalized_map(df.columns), ["Zona"])
    if zona_col:
        df = df[~df[zona_col].astype(str).str.strip().str.lower().isin(
            ["almendralejo", "requena", "cari√±ena", "carinena"]
        )]

    # Eliminar Variedad
    var_col = safe_get_col(build_normalized_map(df.columns), ["Variedad"])
    if var_col and var_col in df.columns:
        df.drop(columns=[var_col], inplace=True)

    # Verificador en may√∫sculas
    verificador_col = safe_get_col(build_normalized_map(df.columns), ["Verificador"])
    if verificador_col:
        df[verificador_col] = df[verificador_col].astype(str).str.upper()

    # Orden de columnas como MASTER
    master_cols = list(eRVC_df.columns)
    common_in_master = [c for c in master_cols if c in df.columns]
    extras = [c for c in df.columns if c not in master_cols]
    ordered = common_in_master + extras
    df = df[ordered]

    return df

def generar_reporte_errores(df):
    errores = []
    pattern = r'^[A-Z]\d{8}$|^\d{8}[A-Z]$'

    if "nifLliurador" in df.columns and "Verificador" in df.columns:
        mask_nif = ~df["nifLliurador"].astype(str).str.strip().str.upper().str.fullmatch(pattern, na=False)
        if mask_nif.any():
            err_nif = (
                df[mask_nif]
                .groupby("Verificador").size()
                .reset_index(name="Cantidad")
            )
            err_nif["Tipo error"] = "Error Introducci√≥n NIF"
            errores.append(err_nif)

    if "tiquetBascula" in df.columns and "Verificador" in df.columns:
        mask_tiquet = df["tiquetBascula"].isna() | (df["tiquetBascula"].astype(str).str.strip() == "")
        if mask_tiquet.any():
            err_tiq = (
                df[mask_tiquet]
                .groupby("Verificador").size()
                .reset_index(name="Cantidad")
            )
            err_tiq["Tipo error"] = "Error Introducci√≥n tiquet"
            errores.append(err_tiq)

    if errores:
        return pd.concat(errores, ignore_index=True)
    else:
        return pd.DataFrame(columns=["Verificador", "Cantidad", "Tipo error"])

# ------------------------------
# Streamlit UI
# ------------------------------
st.set_page_config(
    page_title="üìä An√°lisis Discrepancias CAT", 
    layout="wide",
    page_icon="üìä",
    initial_sidebar_state="expanded"
)

# CSS personalizado para mejorar la apariencia
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 10px;
        margin-bottom: 2rem;
        text-align: center;
        color: white;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    .metric-card {
        background: white;
        padding: 1rem;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        border-left: 4px solid #667eea;
        margin: 0.5rem 0;
    }
    .success-card {
        background: linear-gradient(135deg, #28a745 0%, #20c997 100%);
        color: white;
        padding: 1.5rem;
        border-radius: 10px;
        text-align: center;
        margin: 1rem 0;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    .success-card h3 {
        margin: 0 0 0.5rem 0;
        font-size: 1.2rem;
    }
    .success-card p {
        margin: 0;
        opacity: 0.9;
    }
    
    /* Mejorar apariencia de elementos Streamlit */
    .stSelectbox > div > div {
        background-color: #f8f9fa;
        border-radius: 8px;
    }
    .stMultiSelect > div > div {
        border-radius: 8px;
    }
    .stFileUploader > div {
        border-radius: 8px;
        border: 2px dashed #667eea;
    }
    
    /* Mejorar tablas */
    .dataframe {
        border-radius: 8px;
        overflow: hidden;
    }
    
    /* Sidebar styling */
    .css-1d391kg {
        background-color: #f8f9fa;
    }
</style>
""", unsafe_allow_html=True)

# Encabezado principal con dise√±o mejorado
st.markdown("""
<div class="main-header">
    <h1>üìä An√°lisis de Discrepancias CAT</h1>
    <p>Sistema de comparaci√≥n entre eRVC y Extranet</p>
</div>
""", unsafe_allow_html=True)

# Funci√≥n para crear m√©tricas modernas
def create_metric_card(title, value, description="", icon="üìä"):
    if ui is not None:
        try:
            return ui.metric_card(
                title=title,
                content=str(value),
                description=description,
                key=f"metric_{title.replace(' ', '_').lower()}"
            )
        except:
            pass
    
    # Fallback a m√©tricas est√°ndar con estilo mejorado
    st.markdown(f"""
    <div class="metric-card">
        <h4 style="margin: 0; color: #667eea;">{icon} {title}</h4>
        <h2 style="margin: 0.5rem 0; color: #333;">{value}</h2>
        <p style="margin: 0; color: #666; font-size: 0.9rem;">{description}</p>
    </div>
    """, unsafe_allow_html=True)

# Sidebar para carga de archivos
with st.sidebar:
    st.header("üìÅ Carga de Archivos")
    
    eRVC_file = st.file_uploader(
        "üìã Archivo eRVC (MASTER)", 
        type=["xlsx", "xls"],
        help="Archivo principal de referencia"
    )
    
    extranet_file = st.file_uploader(
        "üåê Archivo Extranet", 
        type=["xlsx", "xls"],
        help="Archivo de declaraciones del verificador"
    )

if eRVC_file and extranet_file:
    try:
        # Cargar y limpiar eRVC
        eRVC_original = pd.read_excel(eRVC_file)
        eRVC_df = limpiar_eRVC(eRVC_original)
        st.success(f"‚úÖ eRVC cargado y procesado: {len(eRVC_df)} registros (de {len(eRVC_original)} originales)")
        
        # Limpiar Extranet
        extranet_df = limpiar_extranet(extranet_file.read(), eRVC_original)
        st.success(f"‚úÖ Extranet procesado: {len(extranet_df)} registros")
        
        # M√©tricas principales con dise√±o moderno
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            create_metric_card(
                "Registros eRVC", 
                f"{len(eRVC_df):,}",
                "Archivo maestro",
                "üìã"
            )
        
        with col2:
            create_metric_card(
                "Registros Extranet", 
                f"{len(extranet_df):,}",
                "Despu√©s de limpieza",
                "üåê"
            )
        
        with col3:
            common_cols = set(eRVC_df.columns) & set(extranet_df.columns)
            create_metric_card(
                "Columnas Comunes", 
                len(common_cols),
                "Para comparaci√≥n",
                "üîó"
            )
        
        with col4:
            if 'nipd' in extranet_df.columns:
                unique_nipd = extranet_df['nipd'].nunique()
                create_metric_card(
                    "NIPD √önicos", 
                    f"{unique_nipd:,}",
                    "En Extranet",
                    "üè∑Ô∏è"
                )
        
        # Reporte de errores con dise√±o mejorado
        st.header("üö® Reporte de Errores")
        errores_df = generar_reporte_errores(extranet_df)
        
        if not errores_df.empty:
            # Mostrar tabla de errores con iconos
            st.dataframe(
                errores_df,
                use_container_width=True,
                column_config={
                    "Verificador": st.column_config.TextColumn(
                        "üë§ Verificador",
                        help="Identificador del verificador"
                    ),
                    "Cantidad": st.column_config.NumberColumn(
                        "üìä Cantidad",
                        help="N√∫mero de errores detectados"
                    ),
                    "Tipo error": st.column_config.TextColumn(
                        "‚ö†Ô∏è Tipo de Error",
                        help="Categor√≠a del error encontrado"
                    )
                }
            )
            
            # Gr√°fico de errores con colores modernos
            import plotly.express as px
            fig = px.bar(
                errores_df, 
                x="Verificador", 
                y="Cantidad", 
                color="Tipo error",
                title="üìä Distribuci√≥n de Errores por Verificador",
                color_discrete_sequence=["#FF6B6B", "#4ECDC4", "#45B7D1", "#96CEB4"]
            )
            fig.update_layout(
                plot_bgcolor="rgba(0,0,0,0)",
                paper_bgcolor="rgba(0,0,0,0)",
                font=dict(family="Arial, sans-serif")
            )
            st.plotly_chart(fig, use_container_width=True)
        else:
            # Mensaje de √©xito mejorado
            st.markdown("""
            <div class="success-card">
                <h3>‚úÖ Excelente!</h3>
                <p>No se detectaron errores de introducci√≥n en los datos</p>
            </div>
            """, unsafe_allow_html=True)
        
        # An√°lisis de discrepancias con dise√±o mejorado
        st.header("üîç An√°lisis de Discrepancias")
        
        # Tip visual mejorado
        st.markdown("""
        <div style="background-color: #f8f9fa; padding: 15px; border-radius: 10px; margin: 10px 0; border-left: 4px solid #007bff;">
            <p style="margin: 0; color: #495057; font-size: 12px;">üí° <strong>Tip:</strong> Selecciona bodegas espec√≠ficas para un an√°lisis m√°s detallado de las discrepancias</p>
        </div>
        """, unsafe_allow_html=True)
        
        if 'nipd' in extranet_df.columns and 'nomCeller' in extranet_df.columns:
            # Crear opciones combinando nipd y nomCeller
            extranet_unique = extranet_df[['nipd', 'nomCeller']].drop_duplicates().dropna()
            opciones_bodegas = [f"{row['nipd']} - {row['nomCeller']}" for _, row in extranet_unique.iterrows()]
            opciones_bodegas = sorted(opciones_bodegas)
            
            bodegas_seleccionadas = st.multiselect(
                "üè≠ Seleccionar Bodegas",
                opciones_bodegas,
                default=opciones_bodegas[:5] if len(opciones_bodegas) > 5 else opciones_bodegas,
                help="Elige las bodegas que quieres analizar (nipd - nombre)"
            )
            
            if bodegas_seleccionadas:
                # Extraer los nipd de las opciones seleccionadas
                nipds_seleccionados = [opcion.split(' - ')[0] for opcion in bodegas_seleccionadas]
                extranet_filtrado = extranet_df[extranet_df['nipd'].isin(nipds_seleccionados)]
                
                # M√©tricas de selecci√≥n con dise√±o moderno
                col1, col2 = st.columns(2)
                with col1:
                    create_metric_card(
                        "Bodegas Seleccionadas", 
                        len(bodegas_seleccionadas),
                        f"De {len(opciones_bodegas)} disponibles",
                        "üè≠"
                    )
                with col2:
                    create_metric_card(
                        "Registros Filtrados", 
                        f"{len(extranet_filtrado):,}",
                        f"De {len(extranet_df):,} totales",
                        "üìä"
                    )
        
        # Vista de datos
        st.header("üìã Vista de Datos")
        
        # Pesta√±a para datos originales
        with st.expander("üìã Ver eRVC Original", expanded=False):
            st.dataframe(eRVC_original.head(100), use_container_width=True)
        
        # Mostrar datos procesados lado a lado
        st.subheader("üìä Datos Procesados")
        col1, col2 = st.columns(2)
        
        # Aplicar el mismo filtro de bodegas a eRVC si existe
        eRVC_display = eRVC_df
        if 'bodegas_seleccionadas' in locals() and bodegas_seleccionadas and 'nipd' in eRVC_df.columns:
            # Usar los mismos nipd seleccionados
            nipds_seleccionados = [opcion.split(' - ')[0] for opcion in bodegas_seleccionadas]
            eRVC_display = eRVC_df[eRVC_df['nipd'].isin(nipds_seleccionados)]
        
        with col1:
            st.markdown("**üßπ eRVC Procesado**")
            if 'bodegas_seleccionadas' in locals() and bodegas_seleccionadas:
                st.caption(f"Filtrado por {len(bodegas_seleccionadas)} bodegas seleccionadas")
            st.dataframe(eRVC_display.head(50), use_container_width=True, height=400)
            
        with col2:
            st.markdown("**üåê Extranet Procesado**")
            display_df = extranet_filtrado if 'extranet_filtrado' in locals() else extranet_df
            if 'bodegas_seleccionadas' in locals() and bodegas_seleccionadas:
                st.caption(f"Filtrado por {len(bodegas_seleccionadas)} bodegas seleccionadas")
            st.dataframe(display_df.head(50), use_container_width=True, height=400)
        
        # Exportaci√≥n con bot√≥n mejorado
        st.header("üíæ Exportar Resultados")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("üì• Descargar Extranet Procesado", type="primary"):
                output = BytesIO()
                with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                    extranet_df.to_excel(writer, sheet_name='Extranet_Procesado', index=False)
                    if not errores_df.empty:
                        errores_df.to_excel(writer, sheet_name='Reporte_Errores', index=False)
                
                st.download_button(
                    label="üìÅ Descargar archivo Excel",
                    data=output.getvalue(),
                    file_name="extranet_procesado.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
        
        with col2:
            if st.button("üßπ Descargar eRVC Procesado", type="primary"):
                output = BytesIO()
                with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                    # Usar los datos filtrados si existe el filtro
                    data_to_export = eRVC_display if 'eRVC_display' in locals() else eRVC_df
                    data_to_export.to_excel(writer, sheet_name='eRVC_Procesado', index=False)
                
                # Nombre de archivo din√°mico seg√∫n filtro
                filename = "eRVC_procesado_filtrado.xlsx" if 'bodegas_seleccionadas' in locals() and bodegas_seleccionadas else "eRVC_procesado.xlsx"
                
                st.download_button(
                    label="üìÅ Descargar archivo Excel",
                    data=output.getvalue(),
                    file_name=filename,
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
            
    except Exception as e:
        st.error(f"‚ùå Error al procesar los archivos: {str(e)}")
        st.info("üí° Verifica que los archivos tengan el formato correcto y contengan las columnas esperadas.")
else:
    # Mensaje de bienvenida mejorado
    st.info("üëã **¬°Bienvenido!** Sube los archivos eRVC y Extranet para comenzar el an√°lisis.")
    
    # Informaci√≥n adicional con dise√±o atractivo
    st.markdown("""
    ### üìñ Instrucciones de Uso
    
    1. **üìã Carga el archivo eRVC** - Este ser√° tu archivo de referencia (MASTER)
    2. **üåê Carga el archivo Extranet** - Declaraciones del verificador para procesar
    3. **üîç Analiza los resultados** - Revisa discrepancias y errores detectados
    4. **üíæ Exporta los datos** - Descarga los resultados procesados
    
    ### ‚ú® Caracter√≠sticas
    
    - üßπ **Limpieza autom√°tica** de datos Extranet
    - üîç **Detecci√≥n de errores** en NIF y tickets
    - üìä **Visualizaciones interactivas** de discrepancias
    - üè≠ **Filtrado por bodegas** para an√°lisis espec√≠ficos
    - üíæ **Exportaci√≥n** de resultados en Excel
    """)
